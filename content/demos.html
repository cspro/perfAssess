<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
		<title>Demonstrations</title>
	</head>

	<body>
		<nav class="floatingMenu">
			<a href="#approach" class="selected">Approach</a>
			<a href="#exemplars">Exemplars</a>
			<a href="#moreinfo">More Info</a>
		</nav>
		<div class="approachPage">
			<section id="approach">
				<div class="pageHeader">
					<article>
						<div class="chevrons"></div>
						<h1>Demonstrations</h1>
					</article>
				</div>
				<hr />
				<article>
					<div class='brainsharkWrapper'></div>
					<h2>Demonstrations</h2>
					<p>Demonstrations require examinees to engage in a live performance of the targeted knowledge, skills, or abilities (KSAs), where the assessment conditions resemble real-life situations.</p>
					<h5>In general, features of demonstrations include:</h5>
					<ul>
						<li>A live performance</li>
						<li>Evaluation that focuses on both process and product (in contrast to performance tasks)</li>
						<li>The input by subject-matter or professional experts on the scoring criteria</li>
						<li>A high degree of similarity between assessment conditions and conditions of real performance experienced in a particular discipline or domain </li>
					</ul>
				</article>
			</section>
			<section id="exemplars">
				<div class="pageHeader">
					<article>
						<div class="chevrons"></div>
						<h1>Examples of Demonstrations</h1>
					</article>
				</div>
				<hr />
				<article>
					<h3>Below is a list of examples that show some of the ways that demonstrations may be used as performance assessment.</h3>
				</article>
				<hr class="subDivider" />
				<article>
					<h3><a href="http://www.vetassess.com.au/take_a_test/plumbing.cfm">VETASSESS Practical Trade Skill Assessment – Plumbing, Journeyman Examination</a></h3>
					<p>This assessment program requires workers to demonstrate a specific set of job functions, such as might be required of a plumber, to earn a trade certificate or course credit based on their demonstrated skills. </p>
					<p><em>Vetassess. Retrieved November 27, 2012 from</em> <a href="http://www.vetassess.com.au/">http://www.vetassess.com.au/</a></p>
				</article>
				<hr class="subDivider" />
				<article>
					<h3><a href="http://www.stanford.edu/dept/SUSE/SEAL/">Stanford Education Assessment Laboratory (SEAL)</a></h3>
					<p><strong>Click: Assessments/Instruments. Click: Paper Towels</strong><br>
						SEAL conducts assessment research that is both conceptual and methodological (psychometric, statistical, qualitative). This demonstration, requiring students to design and conduct an experiment, is an assessment of scientific reasoning, critical thinking, and inquiry.</p>
					<p><em>Stanford Education Assessment Laboratory. Retrieved November 27,2012 from</em> <a href="http://www.stanford.edu/dept/SUSE/SEAL/">http://www.stanford.edu/dept/SUSE/SEAL/</a></p>
				</article>
			</section>
			<section id="moreinfo">
				<div class="pageHeader">
					<article>
						<div class="chevrons"></div>
						<h1>What Are Demonstrations?</h1>
					</article>
				</div>
				<hr />
				<dl class="accordion">
					<dt><a href="">Definition</a></dt>
					<dd>
						<p>Demonstrations require examinees to engage in a live performance of the targeted knowledge, skills, or abilities (KSAs), where the assessment conditions resemble to a high degree of fidelity in construct-relevant ways the conditions under which the targeted KSAs are typically exercised in a given domain or discipline. Such performances must be scored by trained raters, and evaluation of performance quality tends to focus on both process and work products.</p>
					</dd>

					<dt><a href="">Characteristic Features</a></dt>
					<dd>
						<ul>
							<li>Live performance</li>
							<li>Evaluation focuses on both process and product (in contrast to performance tasks)</li>
							<li>Development of evaluation criteria requires input by subject-matter or professional experts  </li>
							<li>High fidelity, authenticity, or degree of similarity on construct-relevant dimensions between assessment conditions and conditions of real performance experienced in a particular discipline or domain</li>
						</ul>
					</dd>

					<dt><a href="">Common Contexts</a></dt>
					<dd>
						<p>Common contexts include dancing or playing a musical instrument (artistic performances); Olympic diving (athletic or physical performances);  medical diagnosis or English speaking fluency (cognitive performances); driving a car or flying an airplane (psychomotor performances)</p>
					</dd>

					<dt><a href="">Design Variations and Other Considerations</a></dt>
					<dd>
						<p>Although experts agree that evaluation of demonstrations requires the judgments of experts, it is unclear whether this implies that scorers must have domain or content expertise or merely scoring expertise. Regardless of who performs the scoring, however, input from domain experts will always be necessary in some form or another during task construction and the design of the evaluation criteria.</p>
					</dd>

					<dt><a href="">Response Demands</a></dt>
					<dd>
						<p>In a demonstration, examinees are asked to do, perform, create, or construct something. The particular response demands of a given demonstration depend on the domain of interest and the particular assessment context.</p>
						<p>What distinguishes demonstrations from other performance assessment approaches is that the response demands in the assessment context are similar to the response demands of the domain or discipline to which we would like to generalize. For example, in an assessment certifying physicians&rsquo; diagnostic skills, examinees are expected to interact with patients, ask questions, and interpret patient responses. These types of responses are highly similar to, if not the same as, the response demands of a practicing physician. Similarly, in a demonstration of students&rsquo; oral reading fluency, students are asked to read short passages aloud. Thus, the response demand of the assessment matches the response demand of the domain (i.e., oral reading ability) about which we want to make inferences.</p>
					</dd>

					<dt><a href="">Evaluation Criteria and Procedures</a></dt>
					<dd>
						<p>The criteria for evaluating performances are based on both the primary focus of the observation and the goals of the assessment. Performances are commonly scored using rubrics or observational checklists to be completed by trained raters. The range of performance quality represented in these rubrics and checklists ought to be identified in collaboration with domain or discipline experts and reflect the intent of the standards within a domain or discipline.</p>
					</dd>

					<dt><a href="">Administration Time</a></dt>
					<dd>
						<p>Varies from a few minutes (e.g., pull-ups) to 20 minutes (e.g., a dance) or more (e.g., sporting event)</p>
					</dd>

					<dt><a href="">References</a></dt>
					<dd>
						<p>Baxter, G. P., Shavelson, R. J., Goldman, S. R., &amp; Pine, J. (1992). Evaluation of procedure-based scoring for hands-on science assessment. <em>Journal of Educational Measurement</em>, 29, 1-17.</p>
						<p>Behrens, J. T., DiCerbo, K. E., &amp; Ferrara, S. (2012). Intended and unintended deceptions in the use of    simulations. Paper presented at the Technology Enhanced Assessment Symposium. Washington, D.C.</p>
						<p>Bennett, R. E. (1993). On the meanings of constructed response. In R. E. Bennett &amp; W. C. Ward (Eds.), <em>Construction versus choice in cognitive measurement: Issues in constructed response, performance testing, and portfolio assessment </em>(pp. 1-27). Hillsdale, NJ: Lawrence Erlbaum Associates.</p>
						<p>Gitomer, D. H. (1993). Performance assessment and educational measurement. In R. E. Bennett &amp; W. C. Ward (Eds.), <em>Construction versus choice in cognitive measurement: Issues in constructed response, performance testing, and portfolio assessment </em>(pp. 241-263). Hillsdale, NJ: Lawrence Erlbaum Associates.</p>
						<p>Lane, S. (2010). <em>Performance assessment: The state of the art</em>. (SCOPE Student Performance Assessment Series). Stanford, CA: Stanford University, Stanford Center for Opportunity Policy in Education.</p>
						<p>Martin, J. A., Reznick, R. K., Rothman, A., Tamblyn, R. M., &amp; Regehr, G. (1996). Who should rate  candidates in an objective structured clinical examination?<em>Academic Medicine</em>, 71, 170–175.</p>
					</dd>

				</dl>
			</section>
		</div>
	</body>
</html>
